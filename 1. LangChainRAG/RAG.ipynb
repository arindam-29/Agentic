{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f11ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1dc715",
   "metadata": {},
   "source": [
    "1. fetch the data from pdf\n",
    "\n",
    "2. at lesat there should be 200 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c996c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total pages: 383\n"
     ]
    }
   ],
   "source": [
    "# Load the pdf document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(file_path=\"../../Class_Exercise/3-RAG_assignment/book 4 pdf.pdf\")\n",
    "#loader=PyPDFLoader(file_path=\"Arindam Choudhury 108068.pdf\")\n",
    "docs=loader.load()\n",
    "print(\"Number of total pages:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67be9a",
   "metadata": {},
   "source": [
    "3. if chunking(use the sementic chunking technique) required do chunking and then embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac55369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model for SemanticChunker and Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "HF_EMBEDDING = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df493a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total Split documents: 815\n"
     ]
    }
   ],
   "source": [
    "# SemanticChunker and split the document\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "text_splitter=SemanticChunker(\n",
    "    embeddings=HF_EMBEDDING,\n",
    "   breakpoint_threshold_type=\"interquartile\"\n",
    ")\n",
    "documents=text_splitter.split_documents(docs)\n",
    "print(\"Number of total Split documents:\", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451964a",
   "metadata": {},
   "source": [
    "4. store it inside the vector database(use any of them 2. astradb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c501da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_API_ENDPOINT=os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "ASTRA_DB_APPLICATION_TOKEN=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "COLLECTION_NAME=\"astra_vector_langchain\"\n",
    "index_name = \"vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e241728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Astro vector store\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding=HF_EMBEDDING,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f68d53",
   "metadata": {},
   "source": [
    "6. create a retriever pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281093d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to vector storre and create retriever\n",
    "\n",
    "## Adding 15 documents only because of free version times out after general_method_timeout_ms = 30000 ms\n",
    "\n",
    "vector_store.add_documents(documents=documents[0:15])\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\":3}  #get top 3 document \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4564f5",
   "metadata": {},
   "source": [
    "10. then write a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1fa57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "custom_prompt=PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "            If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "            \\nQuestion: {question}\n",
    "            \\nContext: {context}\n",
    "            \\nAnswer:\n",
    "            \"\"\",\n",
    "    input_variables=['context', 'questions']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea3b5b",
   "metadata": {},
   "source": [
    "11. generte a oputput through llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909ccbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "LLM=ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c65bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96da2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "custom_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_prompt\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6f295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided text gives the names of several authors of different papers, including  Manigandan, K. Vijayaraja, G. Durga Revanth, A. V. S., G. Kiran Kumar, Ilaiah Kavati, Koppula Srinivas Rao, Ramalingaswamy Cheruku, Diwakar Tripathi, Y. Narasimha Reddy, Sathya Prakash Racharla, R. C. Anju, Sree Harsha Ramesh, and P.  There is no single author named.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_rag_chain.invoke(\"Who is the Author?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
